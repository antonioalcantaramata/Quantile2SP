{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gurobipy as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data (and base code) for the CFLP_10_10 problem is obtained using the Neur2SP repository. We load the data used for training the NN model.\n",
    "\n",
    "https://github.com/khalil-research/Neur2SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/CFLP_10_10_data.csv', index_col=0)\n",
    "data = data.drop(['10','11','12','13','14','14','15','16','17','18','19'], axis=1)\n",
    "\n",
    "y = data['obj']\n",
    "X = data.drop(['obj'], axis=1, inplace=False)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "msk = np.random.rand(len(X)) < 0.8\n",
    "X_train = X[msk]\n",
    "y_train = y[msk]\n",
    "X_val = X[~msk]\n",
    "y_val = y[~msk]\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = scaler.feature_names_in_)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns = scaler.feature_names_in_)\n",
    "\n",
    "y_train = pd.DataFrame(scaler.fit_transform(y_train.values.reshape(-1, 1)), columns = [y.name])\n",
    "y_mean = scaler.mean_\n",
    "y_std = scaler.scale_\n",
    "y_val = pd.DataFrame(scaler.transform(y_val.values.reshape(-1, 1)), columns = [y.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQNN model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the previously trained IQNN model, so it can be used as a set of piece-wise lienar constraints for representing the second stage objective distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardIncremental(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = np.linspace(0.01, 0.99, num=50, endpoint=True)\n",
    "nn_model = FeedforwardIncremental(input_size=X_train.shape[1], hidden_size=64, output_size=len(q), num_hidden_layers=1, dropout_rate=0)\n",
    "nn_model.load_state_dict(torch.load('Models/CFLP_10_10_model.pt'))\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the CFLP_10_10 problem are obtained also from the Neur2SP repository. \n",
    "\n",
    "https://github.com/khalil-research/Neur2SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/inst_f10_c10_r2.0_iss1_bt1_nsp20000_nse5000_sd7.pkl', 'rb') as f:\n",
    "    data_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFLPProblem(object):\n",
    "    \n",
    "    def __init__(self, inst, network, lambda_tradeoff):\n",
    "        \n",
    "        self.inst = inst\n",
    "        self.inst['recourse_costs'] = 2 * np.max([np.max(self.inst['fixed_costs']), np.max(self.inst['trans_costs'])])\n",
    "        self.network = network\n",
    "        self.mip = None\n",
    "        self.lambda_tradeoff = lambda_tradeoff\n",
    "    \n",
    "    def _make_extensive_model(self, scenarios, alpha):\n",
    "        \"\"\" Formulates two stage extensive form. \"\"\"\n",
    "        demands = scenarios\n",
    "        n_scenarios = len(scenarios)\n",
    "        scenario_prob = 1 / n_scenarios\n",
    "        \n",
    "        model = gp.Model()\n",
    "        var_dict = {}\n",
    "        \n",
    "        # binary variables for each location\n",
    "        objective_fs = 0\n",
    "        for i in range(self.inst['n_facilities']):\n",
    "            var_name = f\"x_in[{i}]\"\n",
    "            var_dict[var_name] = model.addVar(lb=0.0, ub=1.0, vtype=\"B\", name=var_name)\n",
    "            objective_fs += self.inst['fixed_costs'][i]*var_dict[var_name]\n",
    "        model.update()\n",
    "        \n",
    "        objective_stoch = 0\n",
    "        # add either continous or binary second stage serving costs\n",
    "        for s in range(n_scenarios):\n",
    "            for i in range(self.inst['n_facilities']):\n",
    "                for j in range(self.inst['n_customers']):\n",
    "                    var_name = f\"y_{i}_{j}_{s}\"\n",
    "                    if self.inst['integer_second_stage']:\n",
    "                        var_dict[var_name] = model.addVar(lb=0.0, ub=1.0, vtype=\"B\",\n",
    "                                                            name=var_name)\n",
    "                    else:\n",
    "                        var_dict[var_name] = model.addVar(lb=0.0, ub=1.0, vtype=\"C\",\n",
    "                                                            name=var_name)\n",
    "                    objective_stoch += self.inst['trans_costs'][i, j] * var_dict[var_name]\n",
    "        model.update()\n",
    "        \n",
    "        # add either continous or binary second stage recourse costs\n",
    "        for s in range(n_scenarios):\n",
    "            for j in range(self.inst['n_customers']):\n",
    "                var_name = f\"z_{j}_{s}\"\n",
    "                if self.inst['integer_second_stage']:\n",
    "                    var_dict[var_name] = model.addVar(lb=0.0, ub=1.0, vtype=\"B\", name=var_name)\n",
    "                else:\n",
    "                    var_dict[var_name] = model.addVar(lb=0.0, ub=1.0, vtype=\"C\", name=var_name)\n",
    "                objective_stoch += self.inst['recourse_costs'] * var_dict[var_name]\n",
    "        model.update()\n",
    "        \n",
    "        # add demand constraints\n",
    "        for s in range(n_scenarios):\n",
    "            for j in range(self.inst['n_customers']):\n",
    "                cons = var_dict[f\"z_{j}_{s}\"]\n",
    "                for i in range(self.inst['n_facilities']):\n",
    "                    cons += var_dict[f\"y_{i}_{j}_{s}\"]\n",
    "                model.addConstr(cons >= 1, name=f\"d_{j}_{s}\")\n",
    "        \n",
    "        # capacity constraints\n",
    "        for s in range(n_scenarios):\n",
    "            for i in range(self.inst['n_facilities']):\n",
    "                cons = - self.inst['capacities'][i] * var_dict[f\"x_in[{i}]\"]\n",
    "                for j in range(self.inst['n_customers']):\n",
    "                    cons += demands[s][j] * var_dict[f\"y_{i}_{j}_{s}\"]\n",
    "                model.addConstr(cons <= 0, name=f\"c_{i}\")\n",
    "        \n",
    "        # bound tightening constraints\n",
    "        if self.inst['bound_tightening_constrs']:\n",
    "            for s in range(n_scenarios):\n",
    "                for i in range(self.inst['n_facilities']):\n",
    "                    for j in range(self.inst['n_customers']):\n",
    "                        model.addConstr(- var_dict[f\"x_in[{i}]\"] + var_dict[f\"y_{i}_{j}_{s}\"] <= 0, name=f\"t_{i}_{j}_{s}\")\n",
    "        model.update()\n",
    "        \n",
    "        # cvar variables and constraints\n",
    "        var_dict[\"nu\"] = model.addVar(lb=0.0, vtype=\"C\", name='nu')\n",
    "        for s in range(n_scenarios):\n",
    "            var_name = f\"eta_{s}\"\n",
    "            var_dict[var_name] = model.addVar(lb=0.0, vtype=\"C\", name=var_name)\n",
    "            model.addConstr(sum(self.inst['recourse_costs'] * var_dict[f\"z_{j}_{s}\"] for j in range(self.inst['n_customers']))\n",
    "                            + sum(sum(self.inst['trans_costs'][i, j] * var_dict[f\"y_{i}_{j}_{s}\"] for j in range(self.inst['n_customers'])) for i in range(self.inst['n_facilities']))\n",
    "                            - var_dict[\"nu\"] - var_dict[f\"eta_{s}\"] <= 0, \n",
    "                            name=f\"eta_cons_{s}\")\n",
    "        model.update()\n",
    "        \n",
    "        model.setObjective((1+self.lambda_tradeoff)*objective_fs + scenario_prob*objective_stoch\n",
    "                            + self.lambda_tradeoff*(var_dict[\"nu\"] + 1/(1-alpha)*sum(scenario_prob*var_dict[f\"eta_{s}\"] for s in range(n_scenarios))), gp.GRB.MINIMIZE)\n",
    "        exp_val = scenario_prob*objective_stoch\n",
    "        cvar_val = var_dict[\"nu\"] + 1/(1-alpha)*sum(scenario_prob*var_dict[f\"eta_{s}\"] for s in range(n_scenarios))\n",
    "        model.update()\n",
    "        \n",
    "        return model, objective_fs, exp_val, cvar_val\n",
    "    \n",
    "    def solve_extensive(self, n_scenarios, alpha=0.9, gap=0.0001, time_limit=600, threads=1, log_dir=None, node_file_start=None,\n",
    "                        node_file_dir=None, test_seed=0):\n",
    "        \"\"\" Solves the extensive form. \"\"\"\n",
    "\n",
    "        def callback(model, where):\n",
    "            \"\"\" Callback function to log time, bounds, and first stage sol. \"\"\"\n",
    "            if where == gp.GRB.Callback.MIPSOL:\n",
    "                self.ef_solving_results['time'].append(model.cbGet(gp.GRB.Callback.RUNTIME))\n",
    "                self.ef_solving_results['primal'].append(model.cbGet(gp.GRB.Callback.MIPSOL_OBJBST))\n",
    "                self.ef_solving_results['dual'].append(model.cbGet(gp.GRB.Callback.MIPSOL_OBJBND))\n",
    "                self.ef_solving_results['incumbent'].append(model.cbGetSolution(model._x ))\n",
    "\n",
    "        # make extensive form \n",
    "        scenarios = self.get_scenarios(n_scenarios, test_seed)\n",
    "        model, objective_fs, exp_val, cvar_val = self._make_extensive_model(scenarios, alpha)\n",
    "        \n",
    "        # get variables for callback\n",
    "        model.update()\n",
    "        \n",
    "        self.ef_solving_results = {'primal': [], 'dual': [], 'incumbent': [], 'time': []}\n",
    "        ef_fs_vars = []\n",
    "        for i in range(self.inst['n_facilities']):\n",
    "            ef_fs_vars.append(model.getVarByName(f\"x_in[{i}]\"))\n",
    "        model._x = ef_fs_vars\n",
    "\n",
    "        # solve two_sp\n",
    "        if log_dir is not None:\n",
    "            model.setParam(\"LogFile\", log_dir)\n",
    "        if node_file_start is not None:\n",
    "            model.setParam(\"NodefileStart\", node_file_start)\n",
    "            model.setParam(\"NodefileDir\", node_file_dir)\n",
    "        model.setParam(\"MIPGap\", gap)\n",
    "        model.setParam(\"TimeLimit\", time_limit)\n",
    "        model.setParam(\"Threads\", threads)\n",
    "\n",
    "        model.optimize(callback)\n",
    "        return model, objective_fs, exp_val, cvar_val\n",
    "    \n",
    "    def gen_surrogate_mip(self):\n",
    "        #####################################\n",
    "        #    Initialize model variables     #\n",
    "        #####################################\n",
    "        self.mip = gp.Model('mipQ')\n",
    "        x_in = self.mip.addVars(self.inst['n_facilities'], vtype=gp.GRB.BINARY, name='x_in')\n",
    "        self.mip.update()\n",
    "        \n",
    "        # set objective\n",
    "        objective_fs = 0\n",
    "        for i in x_in.keys():\n",
    "            objective_fs += self.inst['fixed_costs'][i] * x_in[i]\n",
    "        #self.mip.setObjective((1+lambda_tradeoff)*objective, gp.GRB.MINIMIZE)\n",
    "        self.mip.update()\n",
    "        \n",
    "        first_stage_vars = {k: self.mip.getVarByName(f'x_in[{k}]')\n",
    "                    for k in range(self.inst['n_facilities'])}\n",
    "        \n",
    "        ##############################\n",
    "        #    Network formulation     #\n",
    "        ##############################\n",
    "        \n",
    "        \n",
    "        x = {}\n",
    "        z = {}\n",
    "        x[0] = {}\n",
    "        z[0] = {}\n",
    "        \n",
    "        x_maxs = {}\n",
    "        x_mins = {}\n",
    "        x_maxs[0] = {}\n",
    "        x_mins[0] = {}\n",
    "        \n",
    "        layer_list = nn.ModuleList([])\n",
    "        for layer in self.network.model.children():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer_list.append(layer)\n",
    "        \n",
    "        l_0 = layer_list[0]\n",
    "        for i in range(l_0.in_features):\n",
    "            x[0][i] = (first_stage_vars[i] - X_mean[i])/X_std[i]\n",
    "            x_maxs[0][i] = (1 - X_mean[i])/X_std[i]\n",
    "            x_mins[0][i] = (0 - X_mean[i])/X_std[i]\n",
    "        self.mip.update()\n",
    "        \n",
    "        for ind, layer in enumerate(layer_list):\n",
    "            l = layer\n",
    "            \n",
    "            #x[ind+1][i] tracks the output of node i of layer ind\n",
    "            #z[ind+1][i] is the binary defining whether node i of layer ind is active\n",
    "            x[ind+1] = {}\n",
    "            z[ind+1] = {}\n",
    "            \n",
    "            x_maxs[ind+1] = {}\n",
    "            x_mins[ind+1] = {}\n",
    "            \n",
    "            for i in range(l.out_features):\n",
    "                #get weights and biases\n",
    "                m = l.weight.detach().numpy()[i]\n",
    "                b = l.bias.detach().numpy()[i]\n",
    "                \n",
    "                #compute upper and lower bounds\n",
    "                ub = sum(x_maxs[ind][j] * max(0,m[j]) + x_mins[ind][j] * min(0,m[j]) for j in range(l.in_features)) + b\n",
    "                lb = sum(x_mins[ind][j] * max(0,m[j]) + x_maxs[ind][j] * min(0,m[j]) for j in range(l.in_features)) + b\n",
    "                x_maxs[ind+1][i] = ub\n",
    "                x_mins[ind+1][i] = lb\n",
    "                \n",
    "                if ind < len(layer_list) - 1:\n",
    "                    # Define vars\n",
    "                    x[ind+1][i] = self.mip.addVar(0, max(0,ub), name='x_' + str(ind+1) + '_' + str(i))\n",
    "                    z[ind+1][i] = self.mip.addVar(0, 1, vtype=gp.GRB.BINARY, name='z_' + str(ind+1) + '_' + str(i))\n",
    "                    # Big-M representation of node i\n",
    "                    self.mip.addConstr(x[ind+1][i] >= sum(x[ind][j] * m[j] for j in range(l.in_features)) + b)\n",
    "                    self.mip.addConstr(x[ind+1][i] <= sum(x[ind][j] * m[j] for j in range(l.in_features)) + b - lb*(1-z[ind+1][i]))\n",
    "                    self.mip.addConstr(x[ind+1][i] <= ub * z[ind+1][i])\n",
    "                else:\n",
    "                    if i == 0:\n",
    "                        x[ind+1][i] = self.mip.addVar(lb=lb, ub=ub, name='x_' + str(ind+1) + '_' + str(i))\n",
    "                        self.mip.addConstr(x[ind+1][i] == sum(x[ind][j] * m[j] for j in range(l.in_features)) + b)\n",
    "                    else:\n",
    "                        x[ind+1][i] = self.mip.addVar(0, max(0,ub), name='x_' + str(ind+1) + '_' + str(i))\n",
    "                        z[ind+1][i] = self.mip.addVar(0, 1, vtype=gp.GRB.BINARY, name='z_' + str(ind+1) + '_' + str(i))\n",
    "                        self.mip.addConstr(x[ind+1][i] >= sum(x[ind][j] * m[j] for j in range(l.in_features)) + b)\n",
    "                        self.mip.addConstr(x[ind+1][i] <= sum(x[ind][j] * m[j] for j in range(l.in_features)) + b - lb*(1-z[ind+1][i]))\n",
    "                        self.mip.addConstr(x[ind+1][i] <= ub * z[ind+1][i])\n",
    "            \n",
    "            self.mip.update()\n",
    "            \n",
    "        q_vars = {}\n",
    "        for i in range(l.out_features):\n",
    "            # Saving final incremental quantiles\n",
    "            q_vars[i] = self.mip.addVar(lb=-gp.GRB.INFINITY, name='q_vars_' + str(i))\n",
    "            if i == 0:\n",
    "                self.mip.addConstr(q_vars[i] == x[ind+1][i])\n",
    "            else:\n",
    "                self.mip.addConstr(q_vars[i] == x[ind+1][i] + q_vars[i-1])\n",
    "        self.mip.update()\n",
    "        \n",
    "        q_distd = {}\n",
    "        objective_cvar = 0\n",
    "        objective_mean = 0\n",
    "        for i in range(l.out_features):\n",
    "            q_distd[i] = self.mip.addVar(lb=-gp.GRB.INFINITY, name='q_vars_distd_' + str(i))\n",
    "            self.mip.addConstr(q_distd[i] == q_vars[i]*y_std[0] + y_mean[0])\n",
    "            if i < 35: # This index indicates the quantile of the distribution. 35th quantile represents VaR 70\n",
    "                objective_mean += q_distd[i]\n",
    "            else:\n",
    "                objective_mean += q_distd[i]\n",
    "                objective_cvar += q_distd[i]\n",
    "        self.mip.update()\n",
    "        \n",
    "        self.mip.setObjective((1+self.lambda_tradeoff)*objective_fs + (1/50)*objective_mean + (self.lambda_tradeoff/15)*objective_cvar, gp.GRB.MINIMIZE)\n",
    "        self.mip.update()\n",
    "    \n",
    "    def optimize(self, gap=0.0001, threads=8):\n",
    "        self.mip.setParam('Threads', threads)\n",
    "        self.mip.setParam('MIPGap', gap)\n",
    "        self.mip.update()\n",
    "        \n",
    "        self.mip.optimize()\n",
    "    \n",
    "    def get_scenarios(self, n_scenarios, test_seed):\n",
    "        rng = np.random.RandomState()\n",
    "        rng.seed(n_scenarios + test_seed)\n",
    "        scenarios = [] \n",
    "        for _ in range(n_scenarios):\n",
    "            scenarios.append(rng.randint(5, 35 + 1, size=self.inst['n_customers']))\n",
    "\n",
    "        return scenarios\n",
    "    \n",
    "    def evaluate_sol(self, sol, n_scenarios, alpha, test_seed):\n",
    "        # We can run the extensive model with fixed first-stage decision variables to check the quality of the solution\n",
    "        scenarios = self.get_scenarios(n_scenarios, test_seed)\n",
    "        model, objective_fs, exp_val, cvar_val = self._make_extensive_model(scenarios, alpha)\n",
    "        model.update()\n",
    "        \n",
    "        for ind, var in sol.items():\n",
    "            model.getVarByName(var.VarName).lb = np.abs(np.round(var.X))\n",
    "            model.getVarByName(var.VarName).ub = np.abs(np.round(var.X))\n",
    "        model.update()\n",
    "        \n",
    "        model.setParam(\"OutputFlag\", 0)\n",
    "        model.setParam('Threads', 8)\n",
    "        model.setParam('MIPGap', 0.0005)\n",
    "        model.update()\n",
    "        \n",
    "        model.optimize()\n",
    "        obj = model.getObjective()\n",
    "        \n",
    "        return obj.getValue(), objective_fs.getValue(), exp_val.getValue(), cvar_val.getValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Threads to value 8\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (mac64[rosetta2] - Darwin 23.6.0 23G93)\n",
      "\n",
      "CPU model: Apple M3 Pro\n",
      "Thread count: 11 physical cores, 11 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 440 rows, 337 columns and 8431 nonzeros\n",
      "Model fingerprint: 0xc9a8ebee\n",
      "Variable types: 214 continuous, 123 integer (123 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-06, 8e+03]\n",
      "  Objective range  [2e-02, 2e+03]\n",
      "  Bounds range     [7e-03, 7e+00]\n",
      "  RHS range        [2e-16, 8e+03]\n",
      "Presolve removed 401 rows and 301 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 39 rows, 36 columns, 270 nonzeros\n",
      "Variable types: 13 continuous, 23 integer (23 binary)\n",
      "Found heuristic solution: objective 41516.657267\n",
      "Found heuristic solution: objective 16218.906859\n",
      "\n",
      "Root relaxation: objective 8.015011e+03, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 8015.01094    0    4 16218.9069 8015.01094  50.6%     -    0s\n",
      "H    0     0                    12322.923447 8015.01094  35.0%     -    0s\n",
      "H    0     0                    10879.530196 8015.01094  26.3%     -    0s\n",
      "     0     0 8224.52714    0    5 10879.5302 8224.52714  24.4%     -    0s\n",
      "     0     0 8792.45326    0    7 10879.5302 8792.45326  19.2%     -    0s\n",
      "     0     0 8792.45326    0    7 10879.5302 8792.45326  19.2%     -    0s\n",
      "     0     0 8792.45326    0   10 10879.5302 8792.45326  19.2%     -    0s\n",
      "H    0     0                    10804.964631 8792.45326  18.6%     -    0s\n",
      "     0     0 8792.45326    0    8 10804.9646 8792.45326  18.6%     -    0s\n",
      "     0     0 9372.52808    0    4 10804.9646 9372.52808  13.3%     -    0s\n",
      "     0     0 9373.73081    0    5 10804.9646 9373.73081  13.2%     -    0s\n",
      "     0     0 9607.57670    0    9 10804.9646 9607.57670  11.1%     -    0s\n",
      "     0     0 9713.64216    0    8 10804.9646 9713.64216  10.1%     -    0s\n",
      "     0     0 9766.10511    0    8 10804.9646 9766.10511  9.61%     -    0s\n",
      "     0     0 9767.52830    0    8 10804.9646 9767.52830  9.60%     -    0s\n",
      "     0     0 9769.07866    0    9 10804.9646 9769.07866  9.59%     -    0s\n",
      "     0     0 9770.44630    0    9 10804.9646 9770.44630  9.57%     -    0s\n",
      "     0     0 9793.15625    0   10 10804.9646 9793.15625  9.36%     -    0s\n",
      "     0     0 9795.50702    0    9 10804.9646 9795.50702  9.34%     -    0s\n",
      "     0     0 9828.51728    0    9 10804.9646 9828.51728  9.04%     -    0s\n",
      "     0     0 9833.64746    0    9 10804.9646 9833.64746  8.99%     -    0s\n",
      "     0     0 9840.14232    0    8 10804.9646 9840.14232  8.93%     -    0s\n",
      "     0     0 10141.1086    0    9 10804.9646 10141.1086  6.14%     -    0s\n",
      "     0     0 10254.8888    0    9 10804.9646 10254.8888  5.09%     -    0s\n",
      "     0     0 10391.4778    0    9 10804.9646 10391.4778  3.83%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 2\n",
      "  MIR: 15\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 1 nodes (131 simplex iterations) in 0.03 seconds (0.01 work units)\n",
      "Thread count was 8 (of 11 available processors)\n",
      "\n",
      "Solution count 5: 10805 10879.5 12322.9 ... 41516.7\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.080496463094e+04, best bound 1.080496463094e+04, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "cflp = CFLPProblem(data_params, nn_model, lambda_tradeoff=0.5)\n",
    "cflp.gen_surrogate_mip()\n",
    "cflp.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First-stage heuristic decisions are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <gurobi.Var x_in[0] (value 0.0)>,\n",
       " 1: <gurobi.Var x_in[1] (value 0.0)>,\n",
       " 2: <gurobi.Var x_in[2] (value 0.0)>,\n",
       " 3: <gurobi.Var x_in[3] (value 1.0)>,\n",
       " 4: <gurobi.Var x_in[4] (value 1.0)>,\n",
       " 5: <gurobi.Var x_in[5] (value 1.0)>,\n",
       " 6: <gurobi.Var x_in[6] (value 0.0)>,\n",
       " 7: <gurobi.Var x_in[7] (value 1.0)>,\n",
       " 8: <gurobi.Var x_in[8] (value 0.0)>,\n",
       " 9: <gurobi.Var x_in[9] (value 1.0)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_stage_vars = {k: cflp.mip.getVarByName(f'x_in[{k}]')\n",
    "                for k in range(data_params['n_facilities'])}\n",
    "first_stage_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a small evaluation of the heuristic solution quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_obj = 0\n",
    "fs_obj = 0\n",
    "exp_obj = 0\n",
    "cvar_obj = 0\n",
    "for i in range(10):\n",
    "    obj, fs, exp, cvar = cflp.evaluate_sol(first_stage_vars, 500, 0.7, i)\n",
    "    true_obj += obj\n",
    "    fs_obj += fs\n",
    "    exp_obj += exp \n",
    "    cvar_obj += cvar\n",
    "true_obj = true_obj/10\n",
    "fs_obj = fs_obj/10\n",
    "exp_obj = exp_obj/10\n",
    "cvar_obj = cvar_obj/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted objective: 11178.31185622652\n",
      "First-stage cost: 6235.0\n",
      "Second-stage expected value: 879.8312765035223\n",
      "Second-stage CVaR value: 1891.9611594445446\n"
     ]
    }
   ],
   "source": [
    "print('Weighted objective:', true_obj)\n",
    "print('First-stage cost:', fs_obj)\n",
    "print('Second-stage expected value:', exp_obj)\n",
    "print('Second-stage CVaR value:', cvar_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensive form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could run the extensive form of the optimization problem, which would take a longer time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cflp = CFLPProblem(data_params, nn_model, lambda_tradeoff=0.5)\n",
    "ext_model, objective_fs, exp_val, cvar_val = cflp.solve_extensive(n_scenarios=500, alpha=0.7, threads=8, time_limit=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weighted objective:', ext_model.getObjective().getValue())\n",
    "print('First-stage cost:', objective_fs.getValue())\n",
    "print('Second-stage expected value:', exp_val.getValue())\n",
    "print('Second-stage CVaR value:', cvar_val.getValue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
